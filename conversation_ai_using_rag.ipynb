{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM24Uxa+AUooV0GnnB3UCsr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddhartha-alexander/Retrieval-Augmented-Generation-RAG-Based-Conversational-AI-Chatbot/blob/main/conversation_ai_using_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "mfKCmV_9F9Zs"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain_community langchain_Chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrieval-Augmented Generation (RAG) Based Conversational AI Chatbot\n",
        "\n",
        "**Domain:** Generative AI | NLP | Information Retrieval  \n",
        "**Project Type:** Applied Machine Learning / GenAI  \n",
        "\n",
        "## üìñ Introduction\n",
        "\n",
        "This project implements a **Retrieval-Augmented Generation (RAG)** based conversational AI system.\n",
        "The chatbot enhances Large Language Model (LLM) responses by retrieving relevant information from\n",
        "external documents before generating answers.\n",
        "\n",
        "By combining **vector-based retrieval** with **LLM generation**, the system produces\n",
        "context-aware, accurate, and less hallucinated responses compared to standard LLM chatbots.\n"
      ],
      "metadata": {
        "id": "81Mgoniwq2PI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "MR3jCYg9IQeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9ZbmlPTXJGKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "file='/content/NIPS-2017-attention-is-all-you-need-Paper.pdf'\n",
        "loader=PyPDFLoader(file)\n",
        "doc=loader.load_and_split()"
      ],
      "metadata": {
        "id": "zvRdq3i3JmI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc[0]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jbDCQFjfJ5ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(doc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zkHW4-LKn7g",
        "outputId": "b1f73c84-a119-46e1-d710-8c745ccb23ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split The Data**"
      ],
      "metadata": {
        "id": "JxpYCPgSJ_ie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_split=CharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len\n",
        ")"
      ],
      "metadata": {
        "id": "VdBY7aNVJ7vG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Segmentation**"
      ],
      "metadata": {
        "id": "1dwmr4I6Kbs_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts=text_split.split_documents(doc)"
      ],
      "metadata": {
        "id": "q7O3iCONKVAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww1TJQgkKjUa",
        "outputId": "5bd66ef3-bd9e-418b-aec6-88ea0d366b67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'producer': 'PyPDF2', 'creator': 'PyPDF', 'creationdate': '', 'subject': 'Neural Information Processing Systems http://nips.cc/', 'publisher': 'Curran Associates, Inc.', 'language': 'en-US', 'created': '2017', 'eventtype': 'Poster', 'description-abstract': 'The dominant sequence transduction models are based on complex recurrent orconvolutional neural networks in an encoder and decoder configuration. The best performing such models also connect the encoder and decoder through an attentionm echanisms.  We propose a novel, simple network architecture based solely onan attention mechanism, dispensing with recurrence and convolutions entirely.Experiments on two machine translation tasks show these models to be superiorin quality while being more parallelizable and requiring significantly less timeto train. Our single model with 165 million parameters, achieves 27.5 BLEU onEnglish-to-German translation, improving over the existing best ensemble result by over 1 BLEU. On English-to-French translation, we outperform the previoussingle state-of-the-art with model by 0.7 BLEU, achieving a BLEU score of 41.1.', 'title': 'Attention is All you Need', 'date': '2017', 'moddate': '2018-02-12T21:22:10-08:00', 'published': '2017', 'type': 'Conference Proceedings', 'firstpage': '5998', 'book': 'Advances in Neural Information Processing Systems 30', 'description': 'Paper accepted and presented at the Neural Information Processing Systems Conference (http://nips.cc/)', 'editors': 'I. Guyon and U.V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett', 'author': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, ≈Åukasz Kaiser, Illia Polosukhin', 'lastpage': '6008', 'source': '/content/NIPS-2017-attention-is-all-you-need-Paper.pdf', 'total_pages': 11, 'page': 0, 'page_label': '1'}, page_content='Attention Is All You Need\\nAshish Vaswani‚àó\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer‚àó\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar‚àó\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit‚àó\\nGoogle Research\\nusz@google.com\\nLlion Jones‚àó\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez‚àó‚Ä†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\n≈Åukasz Kaiser ‚àó\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin‚àó‚Ä°\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring signiÔ¨Åcantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.0 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature.\\n1 Introduction\\nRecurrent neural networks, long short-term memory [12] and gated recurrent [7] neural networks\\nin particular, have been Ô¨Årmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [ 29, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [31, 21, 13].\\n‚àóEqual contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the Ô¨Årst Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefÔ¨Åcient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n‚Ä†Work performed while at Google Brain.\\n‚Ä°Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.')"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mv22LlKqKkRZ",
        "outputId": "df6671a3-d47c-4ead-c372-28e43bf8d84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**embeddings**"
      ],
      "metadata": {
        "id": "e90QDGwIKsjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "embedding_model=HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n"
      ],
      "metadata": {
        "id": "p0CVzI0dKlt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataBase Creation**"
      ],
      "metadata": {
        "id": "LeBEXQMbLPnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb=Chroma(\n",
        "    collection_name='sid',\n",
        "    embedding_function=embedding_model\n",
        ")"
      ],
      "metadata": {
        "id": "nfV7TStzLCSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2-pIV6tLw0s",
        "outputId": "795cf3e0-1499-4b09-bcc7-663881bf5c5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7cf823ec2bd0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**inserting Files into database**"
      ],
      "metadata": {
        "id": "oKMsTjaBLlvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "storage_id=vectordb.add_documents(texts)"
      ],
      "metadata": {
        "id": "PfjwmfGwLg0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "storage_id[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "jXVOVynPL1jw",
        "outputId": "67f4292e-23fa-4d53-b8b5-af06eba445b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3c8f23c2-3fb1-4a38-b0b5-a58bf443f422'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "storage_id[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NR5iAQhlL531",
        "outputId": "80b5244c-a794-411c-88a9-29c031fc4070"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ae4c3c2a-261c-46e6-94df-88feabb5dd60'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Similarity Search**"
      ],
      "metadata": {
        "id": "Q6m0AMsNMEyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res=vectordb.similarity_search(\n",
        "    query='What problem does the Transformer architecture aim to solve?',\n",
        "    k=2\n",
        ")"
      ],
      "metadata": {
        "id": "Zkxwp9C1L9md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "id": "fqdPeCW8MbdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the retrivals\n",
        "a.retrever\n",
        "b.llm"
      ],
      "metadata": {
        "id": "8dx1M0zNMrNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriver=vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "2AKjNbI4McIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer,AutoModelForSeq2SeqLM,pipeline"
      ],
      "metadata": {
        "id": "doEviNJ3M-Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained('google/flan-t5-base')"
      ],
      "metadata": {
        "id": "qxj0fGn9NS1n",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizer.pad_token is not None:\n",
        "  tokenizer.add_special_tokens({'pad_token':'[PAD]'})"
      ],
      "metadata": {
        "id": "hpFZhsyMOM-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=AutoModelForSeq2SeqLM.from_pretrained('google/flan-t5-base')"
      ],
      "metadata": {
        "id": "dKaQ7wPENrAb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYHBOpPCOhMb",
        "outputId": "0c510d21-9340-4dc7-b112-082e8bcf10bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(32101, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.config.pad_token_id=tokenizer.pad_token_id"
      ],
      "metadata": {
        "id": "RrqPQ2EYOq7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator=pipeline('text2text-generation',model=model,tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUBqta3GN3w4",
        "outputId": "05c60419-3993-47f9-f2ba-29cbcc535342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import HuggingFacePipeline\n",
        "llm=HuggingFacePipeline(pipeline=generator)"
      ],
      "metadata": {
        "id": "0tDr7pqdOFN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**prompt design**"
      ],
      "metadata": {
        "id": "BehSuiIvO_0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template=\"\"\"use the context to answer the questions.If you dont know say i dont know.\n",
        "\n",
        "         context:\n",
        "         {context}\n",
        "\n",
        "         question:\n",
        "         {question}\n",
        "\n",
        "          answer\"\"\""
      ],
      "metadata": {
        "id": "pwJfVSwuO8Tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_template=PromptTemplate(\n",
        "    template=template\n",
        ")"
      ],
      "metadata": {
        "id": "Nd_Bn5X2Ph1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain=(\n",
        "    {'context':retriver,'question':RunnablePassthrough()}\n",
        "    |custom_template\n",
        "    |llm\n",
        "    |StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "IULPcdtEPphH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nDrwGwGzQEG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test**"
      ],
      "metadata": {
        "id": "4CJV_-rLQEVR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query='What problem does the Transformer architecture aim to solve?'\n",
        "res=rag_chain.invoke(query)\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "0IE7w-8QQBUL",
        "outputId": "a8381256-201d-4d2b-99e2-50aeb8b03cdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (5382 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'recurrence and convolutions'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "collapsed": true,
        "id": "hk8XInqXQZ2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "def chat(message,history):\n",
        "  bot_message=rag_chain.invoke(message)\n",
        "  history.append((message,bot_message))\n",
        "  return history,history\n",
        "with gr.Blocks() as demo:\n",
        "  chatbot=gr.Chatbot()\n",
        "  msg=gr.Textbox()\n",
        "  clear=gr.Button('clear')\n",
        "  msg.submit(chat, [msg,chatbot], [msg,chatbot])\n",
        "  clear.click(lambda: None, None, chatbot, queue=False)\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "RE9ibqVcRKQD",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚úÖ Conclusion\n",
        "\n",
        "This project demonstrates how Retrieval-Augmented Generation (RAG)\n",
        "can significantly improve the reliability and usefulness of conversational AI systems.\n",
        "The modular design allows easy scaling, dataset replacement, and deployment.\n"
      ],
      "metadata": {
        "id": "1y_JFf5MrIYX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aLtHo-K9Rc0I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}